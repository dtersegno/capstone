{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a69d7e",
   "metadata": {},
   "source": [
    "# Simple neural network predicting ahead of time\n",
    "\n",
    "Using [otexts](https://otexts.com/fpp2/nnetar.html) as a reference.\n",
    "\n",
    "requires tensorflow environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24863c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "#pkerastting\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b4adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "basic_rates_path = '../merged_data/resampled_tudf_minute_basic.csv'\n",
    "rdf = pd.read_csv(basic_rates_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7a0eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_rate_60</th>\n",
       "      <th>tweet_rate_600</th>\n",
       "      <th>time_since_last_tweet_rolling_60</th>\n",
       "      <th>time_since_last_tweet_rolling_600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-29 19:46:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-29 19:47:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-29 19:48:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-29 19:49:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-29 19:50:00+00:00</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.633333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8769</th>\n",
       "      <td>2022-05-05 21:55:00+00:00</td>\n",
       "      <td>0.688653</td>\n",
       "      <td>0.655620</td>\n",
       "      <td>1.453333</td>\n",
       "      <td>1.525292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770</th>\n",
       "      <td>2022-05-05 21:56:00+00:00</td>\n",
       "      <td>0.665937</td>\n",
       "      <td>0.649971</td>\n",
       "      <td>1.504687</td>\n",
       "      <td>1.538542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>2022-05-05 21:57:00+00:00</td>\n",
       "      <td>0.573858</td>\n",
       "      <td>0.643458</td>\n",
       "      <td>1.744298</td>\n",
       "      <td>1.554123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>2022-05-05 21:58:00+00:00</td>\n",
       "      <td>0.645358</td>\n",
       "      <td>0.639689</td>\n",
       "      <td>1.558865</td>\n",
       "      <td>1.563298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8773</th>\n",
       "      <td>2022-05-05 21:59:00+00:00</td>\n",
       "      <td>0.632271</td>\n",
       "      <td>0.636048</td>\n",
       "      <td>1.582716</td>\n",
       "      <td>1.572222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8774 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at  tweet_rate_60  tweet_rate_600  \\\n",
       "0     2022-04-29 19:46:00+00:00            NaN             NaN   \n",
       "1     2022-04-29 19:47:00+00:00            NaN             NaN   \n",
       "2     2022-04-29 19:48:00+00:00            NaN             NaN   \n",
       "3     2022-04-29 19:49:00+00:00            NaN             NaN   \n",
       "4     2022-04-29 19:50:00+00:00       0.275387             NaN   \n",
       "...                         ...            ...             ...   \n",
       "8769  2022-05-05 21:55:00+00:00       0.688653        0.655620   \n",
       "8770  2022-05-05 21:56:00+00:00       0.665937        0.649971   \n",
       "8771  2022-05-05 21:57:00+00:00       0.573858        0.643458   \n",
       "8772  2022-05-05 21:58:00+00:00       0.645358        0.639689   \n",
       "8773  2022-05-05 21:59:00+00:00       0.632271        0.636048   \n",
       "\n",
       "      time_since_last_tweet_rolling_60  time_since_last_tweet_rolling_600  \n",
       "0                                  NaN                                NaN  \n",
       "1                                  NaN                                NaN  \n",
       "2                                  NaN                                NaN  \n",
       "3                                  NaN                                NaN  \n",
       "4                             3.633333                                NaN  \n",
       "...                                ...                                ...  \n",
       "8769                          1.453333                           1.525292  \n",
       "8770                          1.504687                           1.538542  \n",
       "8771                          1.744298                           1.554123  \n",
       "8772                          1.558865                           1.563298  \n",
       "8773                          1.582716                           1.572222  \n",
       "\n",
       "[8774 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34a482",
   "metadata": {},
   "source": [
    "Create a new dataframe of lagged values to input in the NN.\n",
    "\n",
    "Pick a point in time, then get the last T minutes. These could also be spaced at S skipped intervals. This data will be highly redundant, but prepared ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79ef8065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.275387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.293223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.285841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.334971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.403282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.770737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.072661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.066928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.351860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.276283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4996 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "4     0.275387  0.275387  0.275387  0.275387  0.275387  0.275387  0.275387   \n",
       "5     0.293223  0.293223  0.293223  0.293223  0.293223  0.293223  0.293223   \n",
       "6     0.285841  0.285841  0.285841  0.285841  0.285841  0.285841  0.285841   \n",
       "7     0.334971  0.334971  0.334971  0.334971  0.334971  0.334971  0.334971   \n",
       "8     0.403282  0.403282  0.403282  0.403282  0.403282  0.403282  0.403282   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4995  0.770737  0.770737  0.770737  0.770737  0.770737  0.770737  0.770737   \n",
       "4996  1.072661  1.072661  1.072661  1.072661  1.072661  1.072661  1.072661   \n",
       "4997  1.066928  1.066928  1.066928  1.066928  1.066928  1.066928  1.066928   \n",
       "4998  1.351860  1.351860  1.351860  1.351860  1.351860  1.351860  1.351860   \n",
       "4999  1.276283  1.276283  1.276283  1.276283  1.276283  1.276283  1.276283   \n",
       "\n",
       "            7         8         9   ...        11        12        13  \\\n",
       "4     0.275387  0.275387  0.275387  ...  0.275387  0.275387  0.275387   \n",
       "5     0.293223  0.293223  0.293223  ...  0.293223  0.293223  0.293223   \n",
       "6     0.285841  0.285841  0.285841  ...  0.285841  0.285841  0.285841   \n",
       "7     0.334971  0.334971  0.334971  ...  0.334971  0.334971  0.334971   \n",
       "8     0.403282  0.403282  0.403282  ...  0.403282  0.403282  0.403282   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4995  0.770737  0.770737  0.770737  ...  0.770737  0.770737  0.770737   \n",
       "4996  1.072661  1.072661  1.072661  ...  1.072661  1.072661  1.072661   \n",
       "4997  1.066928  1.066928  1.066928  ...  1.066928  1.066928  1.066928   \n",
       "4998  1.351860  1.351860  1.351860  ...  1.351860  1.351860  1.351860   \n",
       "4999  1.276283  1.276283  1.276283  ...  1.276283  1.276283  1.276283   \n",
       "\n",
       "            14        15        16        17        18        19        20  \n",
       "4     0.275387  0.275387  0.275387  0.275387  0.275387  0.275387  0.275387  \n",
       "5     0.293223  0.293223  0.293223  0.293223  0.293223  0.293223  0.293223  \n",
       "6     0.285841  0.285841  0.285841  0.285841  0.285841  0.285841  0.285841  \n",
       "7     0.334971  0.334971  0.334971  0.334971  0.334971  0.334971  0.334971  \n",
       "8     0.403282  0.403282  0.403282  0.403282  0.403282  0.403282  0.403282  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4995  0.770737  0.770737  0.770737  0.770737  0.770737  0.770737  0.770737  \n",
       "4996  1.072661  1.072661  1.072661  1.072661  1.072661  1.072661  1.072661  \n",
       "4997  1.066928  1.066928  1.066928  1.066928  1.066928  1.066928  1.066928  \n",
       "4998  1.351860  1.351860  1.351860  1.351860  1.351860  1.351860  1.351860  \n",
       "4999  1.276283  1.276283  1.276283  1.276283  1.276283  1.276283  1.276283  \n",
       "\n",
       "[4996 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each entry in tweet_rate_60,\n",
    "\n",
    "# create a row in a dataframe with that value and T previous values\n",
    "\n",
    "number_previous_values = 20  #20 minutes before\n",
    "\n",
    "tweet_rate_df = pd.DataFrame([rdf['tweet_rate_60'][:5000]]*(number_previous_values+1)).T\n",
    "tweet_rate_df.dropna(inplace = True)\n",
    "tweet_rate_df.columns = range(len(tweet_rate_df.columns))\n",
    "tweet_rate_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed14e6ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.383798</td>\n",
       "      <td>0.438326</td>\n",
       "      <td>0.419237</td>\n",
       "      <td>0.339178</td>\n",
       "      <td>0.292630</td>\n",
       "      <td>0.319642</td>\n",
       "      <td>0.354769</td>\n",
       "      <td>0.419436</td>\n",
       "      <td>0.415126</td>\n",
       "      <td>0.388040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374363</td>\n",
       "      <td>0.359368</td>\n",
       "      <td>0.350328</td>\n",
       "      <td>0.364023</td>\n",
       "      <td>0.399959</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.275387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.376181</td>\n",
       "      <td>0.383798</td>\n",
       "      <td>0.438326</td>\n",
       "      <td>0.419237</td>\n",
       "      <td>0.339178</td>\n",
       "      <td>0.292630</td>\n",
       "      <td>0.319642</td>\n",
       "      <td>0.354769</td>\n",
       "      <td>0.419436</td>\n",
       "      <td>0.415126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341047</td>\n",
       "      <td>0.374363</td>\n",
       "      <td>0.359368</td>\n",
       "      <td>0.350328</td>\n",
       "      <td>0.364023</td>\n",
       "      <td>0.399959</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.285841</td>\n",
       "      <td>0.293223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.376181</td>\n",
       "      <td>0.383798</td>\n",
       "      <td>0.438326</td>\n",
       "      <td>0.419237</td>\n",
       "      <td>0.339178</td>\n",
       "      <td>0.292630</td>\n",
       "      <td>0.319642</td>\n",
       "      <td>0.354769</td>\n",
       "      <td>0.419436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388040</td>\n",
       "      <td>0.341047</td>\n",
       "      <td>0.374363</td>\n",
       "      <td>0.359368</td>\n",
       "      <td>0.350328</td>\n",
       "      <td>0.364023</td>\n",
       "      <td>0.399959</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.285841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.397581</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.376181</td>\n",
       "      <td>0.383798</td>\n",
       "      <td>0.438326</td>\n",
       "      <td>0.419237</td>\n",
       "      <td>0.339178</td>\n",
       "      <td>0.292630</td>\n",
       "      <td>0.319642</td>\n",
       "      <td>0.354769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415126</td>\n",
       "      <td>0.388040</td>\n",
       "      <td>0.341047</td>\n",
       "      <td>0.374363</td>\n",
       "      <td>0.359368</td>\n",
       "      <td>0.350328</td>\n",
       "      <td>0.364023</td>\n",
       "      <td>0.399959</td>\n",
       "      <td>0.403282</td>\n",
       "      <td>0.334971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.385661</td>\n",
       "      <td>0.397581</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.376181</td>\n",
       "      <td>0.383798</td>\n",
       "      <td>0.438326</td>\n",
       "      <td>0.419237</td>\n",
       "      <td>0.339178</td>\n",
       "      <td>0.292630</td>\n",
       "      <td>0.319642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419436</td>\n",
       "      <td>0.415126</td>\n",
       "      <td>0.388040</td>\n",
       "      <td>0.341047</td>\n",
       "      <td>0.374363</td>\n",
       "      <td>0.359368</td>\n",
       "      <td>0.350328</td>\n",
       "      <td>0.364023</td>\n",
       "      <td>0.399959</td>\n",
       "      <td>0.403282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.784215</td>\n",
       "      <td>0.706482</td>\n",
       "      <td>0.800175</td>\n",
       "      <td>0.762062</td>\n",
       "      <td>0.807633</td>\n",
       "      <td>0.826228</td>\n",
       "      <td>0.793047</td>\n",
       "      <td>0.775613</td>\n",
       "      <td>0.755772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689459</td>\n",
       "      <td>0.704008</td>\n",
       "      <td>0.728153</td>\n",
       "      <td>0.813495</td>\n",
       "      <td>1.019475</td>\n",
       "      <td>0.829359</td>\n",
       "      <td>0.800096</td>\n",
       "      <td>0.809159</td>\n",
       "      <td>1.078092</td>\n",
       "      <td>1.037286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1.072661</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.784215</td>\n",
       "      <td>0.706482</td>\n",
       "      <td>0.800175</td>\n",
       "      <td>0.762062</td>\n",
       "      <td>0.807633</td>\n",
       "      <td>0.826228</td>\n",
       "      <td>0.793047</td>\n",
       "      <td>0.775613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785415</td>\n",
       "      <td>0.689459</td>\n",
       "      <td>0.704008</td>\n",
       "      <td>0.728153</td>\n",
       "      <td>0.813495</td>\n",
       "      <td>1.019475</td>\n",
       "      <td>0.829359</td>\n",
       "      <td>0.800096</td>\n",
       "      <td>0.809159</td>\n",
       "      <td>1.078092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.784215</td>\n",
       "      <td>0.706482</td>\n",
       "      <td>0.800175</td>\n",
       "      <td>0.762062</td>\n",
       "      <td>0.807633</td>\n",
       "      <td>0.826228</td>\n",
       "      <td>0.793047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755772</td>\n",
       "      <td>0.785415</td>\n",
       "      <td>0.689459</td>\n",
       "      <td>0.704008</td>\n",
       "      <td>0.728153</td>\n",
       "      <td>0.813495</td>\n",
       "      <td>1.019475</td>\n",
       "      <td>0.829359</td>\n",
       "      <td>0.800096</td>\n",
       "      <td>0.809159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.784215</td>\n",
       "      <td>0.706482</td>\n",
       "      <td>0.800175</td>\n",
       "      <td>0.762062</td>\n",
       "      <td>0.807633</td>\n",
       "      <td>0.826228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775613</td>\n",
       "      <td>0.755772</td>\n",
       "      <td>0.785415</td>\n",
       "      <td>0.689459</td>\n",
       "      <td>0.704008</td>\n",
       "      <td>0.728153</td>\n",
       "      <td>0.813495</td>\n",
       "      <td>1.019475</td>\n",
       "      <td>0.829359</td>\n",
       "      <td>0.800096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1.276283</td>\n",
       "      <td>1.351860</td>\n",
       "      <td>1.066928</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>0.770737</td>\n",
       "      <td>0.784215</td>\n",
       "      <td>0.706482</td>\n",
       "      <td>0.800175</td>\n",
       "      <td>0.762062</td>\n",
       "      <td>0.807633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793047</td>\n",
       "      <td>0.775613</td>\n",
       "      <td>0.755772</td>\n",
       "      <td>0.785415</td>\n",
       "      <td>0.689459</td>\n",
       "      <td>0.704008</td>\n",
       "      <td>0.728153</td>\n",
       "      <td>0.813495</td>\n",
       "      <td>1.019475</td>\n",
       "      <td>0.829359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4976 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "24    0.383798  0.438326  0.419237  0.339178  0.292630  0.319642  0.354769   \n",
       "25    0.376181  0.383798  0.438326  0.419237  0.339178  0.292630  0.319642   \n",
       "26    0.391300  0.376181  0.383798  0.438326  0.419237  0.339178  0.292630   \n",
       "27    0.397581  0.391300  0.376181  0.383798  0.438326  0.419237  0.339178   \n",
       "28    0.385661  0.397581  0.391300  0.376181  0.383798  0.438326  0.419237   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4995  0.770737  0.784215  0.706482  0.800175  0.762062  0.807633  0.826228   \n",
       "4996  1.072661  0.770737  0.784215  0.706482  0.800175  0.762062  0.807633   \n",
       "4997  1.066928  1.072661  0.770737  0.784215  0.706482  0.800175  0.762062   \n",
       "4998  1.351860  1.066928  1.072661  0.770737  0.784215  0.706482  0.800175   \n",
       "4999  1.276283  1.351860  1.066928  1.072661  0.770737  0.784215  0.706482   \n",
       "\n",
       "            7         8         9   ...        11        12        13  \\\n",
       "24    0.419436  0.415126  0.388040  ...  0.374363  0.359368  0.350328   \n",
       "25    0.354769  0.419436  0.415126  ...  0.341047  0.374363  0.359368   \n",
       "26    0.319642  0.354769  0.419436  ...  0.388040  0.341047  0.374363   \n",
       "27    0.292630  0.319642  0.354769  ...  0.415126  0.388040  0.341047   \n",
       "28    0.339178  0.292630  0.319642  ...  0.419436  0.415126  0.388040   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4995  0.793047  0.775613  0.755772  ...  0.689459  0.704008  0.728153   \n",
       "4996  0.826228  0.793047  0.775613  ...  0.785415  0.689459  0.704008   \n",
       "4997  0.807633  0.826228  0.793047  ...  0.755772  0.785415  0.689459   \n",
       "4998  0.762062  0.807633  0.826228  ...  0.775613  0.755772  0.785415   \n",
       "4999  0.800175  0.762062  0.807633  ...  0.793047  0.775613  0.755772   \n",
       "\n",
       "            14        15        16        17        18        19        20  \n",
       "24    0.364023  0.399959  0.403282  0.334971  0.285841  0.293223  0.275387  \n",
       "25    0.350328  0.364023  0.399959  0.403282  0.334971  0.285841  0.293223  \n",
       "26    0.359368  0.350328  0.364023  0.399959  0.403282  0.334971  0.285841  \n",
       "27    0.374363  0.359368  0.350328  0.364023  0.399959  0.403282  0.334971  \n",
       "28    0.341047  0.374363  0.359368  0.350328  0.364023  0.399959  0.403282  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4995  0.813495  1.019475  0.829359  0.800096  0.809159  1.078092  1.037286  \n",
       "4996  0.728153  0.813495  1.019475  0.829359  0.800096  0.809159  1.078092  \n",
       "4997  0.704008  0.728153  0.813495  1.019475  0.829359  0.800096  0.809159  \n",
       "4998  0.689459  0.704008  0.728153  0.813495  1.019475  0.829359  0.800096  \n",
       "4999  0.785415  0.689459  0.704008  0.728153  0.813495  1.019475  0.829359  \n",
       "\n",
       "[4976 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shift columns\n",
    "for column in tweet_rate_df.columns:\n",
    "    tweet_rate_df[column] = tweet_rate_df[column].shift(column)\n",
    "tweet_rate_df.dropna(inplace = True)\n",
    "tweet_rate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e5cc4",
   "metadata": {},
   "source": [
    "Each column is now a tweet rate (0) or the rate at the `column` minutes before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "380e3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up train-test-split.\n",
    "# no stratify needed. These are numbos.\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweet_rate_df[range(1,20)],tweet_rate_df[0], train_size=0.8, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e7e14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate keras model\n",
    "model = Sequential()\n",
    "\n",
    "#add normal layers\n",
    "model.add(\n",
    "    Dense(number_previous_values, activation = 'relu')\n",
    ")\n",
    "model.add(\n",
    "    Dense(number_previous_values, activation = 'relu')\n",
    ")\n",
    "model.add(\n",
    "    Dense(number_previous_values, activation = 'relu')\n",
    ")\n",
    "#no activation for output\n",
    "model.add(\n",
    "    Dense(1)\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = 'mean_squared_error',\n",
    "    optimizer = 'adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77026d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "WARNING:tensorflow:Layer dense_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 0.5109WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2466 - val_loss: 0.0901\n",
      "Epoch 2/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0499\n",
      "Epoch 3/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0398\n",
      "Epoch 4/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0364\n",
      "Epoch 5/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0332\n",
      "Epoch 6/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0300\n",
      "Epoch 7/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0251\n",
      "Epoch 8/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0209\n",
      "Epoch 9/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0178\n",
      "Epoch 10/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0148\n",
      "Epoch 11/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 12/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 13/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0118\n",
      "Epoch 14/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0115\n",
      "Epoch 15/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0113\n",
      "Epoch 16/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0109\n",
      "Epoch 17/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0109\n",
      "Epoch 18/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0106\n",
      "Epoch 19/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0105\n",
      "Epoch 20/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 21/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0102\n",
      "Epoch 22/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 23/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0101\n",
      "Epoch 24/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 25/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 26/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0098\n",
      "Epoch 27/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 28/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 29/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0098\n",
      "Epoch 30/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0096\n",
      "Epoch 31/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0095\n",
      "Epoch 32/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0098\n",
      "Epoch 33/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0095\n",
      "Epoch 34/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 35/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0096\n",
      "Epoch 36/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 37/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0098\n",
      "Epoch 38/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0094\n",
      "Epoch 39/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0097\n",
      "Epoch 40/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0094\n",
      "Epoch 41/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0092\n",
      "Epoch 42/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0093\n",
      "Epoch 43/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0092\n",
      "Epoch 44/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0092\n",
      "Epoch 45/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0095\n",
      "Epoch 46/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0094\n",
      "Epoch 47/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0092\n",
      "Epoch 48/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0094\n",
      "Epoch 49/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0091\n",
      "Epoch 50/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0092\n",
      "Epoch 51/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0091\n",
      "Epoch 52/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0091\n",
      "Epoch 53/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0091\n",
      "Epoch 54/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0090\n",
      "Epoch 55/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0091\n",
      "Epoch 56/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0091\n",
      "Epoch 57/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0090\n",
      "Epoch 58/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0091\n",
      "Epoch 59/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 60/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 61/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 62/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 63/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 64/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 65/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0090\n",
      "Epoch 66/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 67/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 68/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 69/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0090\n",
      "Epoch 70/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 71/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0090\n",
      "Epoch 72/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "Epoch 74/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 75/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 76/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "Epoch 77/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 78/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0090\n",
      "Epoch 79/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 80/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 81/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "Epoch 82/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "Epoch 83/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 84/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 85/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0091\n",
      "Epoch 86/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 87/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0091\n",
      "Epoch 88/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0089\n",
      "Epoch 89/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0094\n",
      "Epoch 90/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 91/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 92/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0090\n",
      "Epoch 93/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 94/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 95/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0091\n",
      "Epoch 96/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 97/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 98/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 99/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0090\n",
      "Epoch 100/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 101/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0090\n",
      "Epoch 102/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 103/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 104/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 105/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 106/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 107/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 108/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0093\n",
      "Epoch 109/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 112/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 115/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0087\n",
      "Epoch 116/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0091\n",
      "Epoch 117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 118/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 119/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0090\n",
      "Epoch 120/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0090\n",
      "Epoch 121/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 122/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 123/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0093\n",
      "Epoch 124/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 125/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0092\n",
      "Epoch 126/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 127/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0091\n",
      "Epoch 128/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 129/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 130/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 131/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 132/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 133/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0090\n",
      "Epoch 134/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 135/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0091\n",
      "Epoch 136/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0091\n",
      "Epoch 137/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "Epoch 138/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 139/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 140/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 141/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 142/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0089\n",
      "Epoch 143/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 144/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0089\n",
      "Epoch 145/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 146/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 147/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 148/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0092\n",
      "Epoch 149/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 150/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0090\n",
      "Epoch 151/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0091\n",
      "Epoch 152/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 153/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 154/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 155/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 157/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0089\n",
      "Epoch 158/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 159/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0091\n",
      "Epoch 160/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 161/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0089\n",
      "Epoch 162/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 163/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0090\n",
      "Epoch 164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 165/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 166/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 167/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0092\n",
      "Epoch 168/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 169/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 170/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 171/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 172/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 173/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 174/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 175/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 176/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0091\n",
      "Epoch 177/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0090\n",
      "Epoch 178/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 179/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 181/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 182/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0089\n",
      "Epoch 183/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 184/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 185/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0089\n",
      "Epoch 186/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0091\n",
      "Epoch 187/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 188/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 189/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 190/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 191/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0096\n",
      "Epoch 192/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0089\n",
      "Epoch 193/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 194/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 195/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 196/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 197/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 198/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 199/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 200/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 201/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 202/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 203/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.005 - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 204/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 205/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 206/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 207/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 208/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 209/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 210/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0089\n",
      "Epoch 212/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 213/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 214/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 215/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 216/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0089\n",
      "Epoch 217/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 218/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0089\n",
      "Epoch 219/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 220/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 221/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 222/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 223/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0091\n",
      "Epoch 224/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0089\n",
      "Epoch 225/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 226/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 227/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 228/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0092\n",
      "Epoch 229/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0093\n",
      "Epoch 230/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 231/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 232/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 233/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 234/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 235/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 236/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 237/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 238/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0095\n",
      "Epoch 239/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0092\n",
      "Epoch 240/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 241/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 242/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 243/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 244/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 245/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 246/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0089\n",
      "Epoch 247/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 248/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 249/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 250/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 251/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 252/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 253/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0093\n",
      "Epoch 254/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 255/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0092\n",
      "Epoch 256/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0089\n",
      "Epoch 257/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 258/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 259/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 260/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 261/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 262/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 263/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 264/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 265/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 266/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 267/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0094\n",
      "Epoch 268/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0093\n",
      "Epoch 269/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 270/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0093\n",
      "Epoch 271/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0092\n",
      "Epoch 272/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0092\n",
      "Epoch 273/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 274/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0089\n",
      "Epoch 275/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 276/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 277/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 278/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 279/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 280/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 281/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 282/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.005 - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 283/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 284/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 285/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 286/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0091\n",
      "Epoch 287/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0092\n",
      "Epoch 288/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0095\n",
      "Epoch 289/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 290/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 291/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0089\n",
      "Epoch 292/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 293/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 294/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 295/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0091\n",
      "Epoch 296/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 297/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 298/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 299/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 300/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 301/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0091\n",
      "Epoch 302/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 303/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 304/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 305/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.005 - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 306/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 307/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0096\n",
      "Epoch 308/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 309/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 310/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 312/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 314/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0092\n",
      "Epoch 315/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0091\n",
      "Epoch 316/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 317/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 318/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0090\n",
      "Epoch 319/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 320/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 321/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 323/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0095\n",
      "Epoch 324/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 325/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 326/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0091\n",
      "Epoch 327/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 328/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 329/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 330/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 331/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 332/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 333/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 334/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0094\n",
      "Epoch 335/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 336/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0091\n",
      "Epoch 337/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0091\n",
      "Epoch 338/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 339/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 340/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 341/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0090\n",
      "Epoch 342/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 343/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 344/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0098\n",
      "Epoch 345/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0092\n",
      "Epoch 346/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0091\n",
      "Epoch 347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 348/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0091\n",
      "Epoch 349/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 350/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 351/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 352/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 353/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0091\n",
      "Epoch 354/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 355/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0096\n",
      "Epoch 356/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 358/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 359/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 360/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 361/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0095\n",
      "Epoch 362/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 363/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0091\n",
      "Epoch 364/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 365/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0097\n",
      "Epoch 366/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 367/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 368/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0092\n",
      "Epoch 369/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 370/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0091\n",
      "Epoch 371/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 372/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 373/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 374/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 375/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 376/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 377/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 378/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 379/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 380/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 381/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 382/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 383/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 384/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 385/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0091\n",
      "Epoch 386/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0095\n",
      "Epoch 387/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0099\n",
      "Epoch 388/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0094\n",
      "Epoch 389/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 390/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0091\n",
      "Epoch 391/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 392/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 393/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 394/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 395/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.006 - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 396/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0099\n",
      "Epoch 397/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0094\n",
      "Epoch 398/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 399/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 400/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0101\n",
      "Epoch 401/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0099\n",
      "Epoch 402/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0094\n",
      "Epoch 403/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 404/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 405/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0093\n",
      "Epoch 406/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 407/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 408/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 409/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 410/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 411/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0101\n",
      "Epoch 412/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0095\n",
      "Epoch 413/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 414/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 415/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 416/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 417/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0093\n",
      "Epoch 418/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 419/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 420/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 421/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 422/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 423/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 424/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 425/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 426/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 427/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 428/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 429/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 430/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 431/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0093\n",
      "Epoch 434/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0095\n",
      "Epoch 435/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 436/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 437/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 438/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 439/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 440/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0095\n",
      "Epoch 441/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 442/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 443/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 444/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 445/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 446/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 447/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 448/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 449/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 450/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 451/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 452/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 453/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 454/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 455/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 456/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 457/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 458/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0093\n",
      "Epoch 459/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 460/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 461/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 462/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 463/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 464/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 465/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 466/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0095\n",
      "Epoch 467/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 468/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 469/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 470/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 471/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 472/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 473/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0099\n",
      "Epoch 474/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 475/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0098\n",
      "Epoch 476/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 477/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0099\n",
      "Epoch 478/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 479/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 480/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0099\n",
      "Epoch 481/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 482/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 483/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 484/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 485/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 486/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 487/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 488/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 489/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0095\n",
      "Epoch 490/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0092\n",
      "Epoch 491/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 492/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 493/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 494/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0097\n",
      "Epoch 495/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 496/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 497/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 498/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0092\n",
      "Epoch 499/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0093\n",
      "Epoch 500/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 501/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0099\n",
      "Epoch 502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0098\n",
      "Epoch 503/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 504/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 505/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 506/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 507/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 508/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 509/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 510/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 511/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0094\n",
      "Epoch 512/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 513/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 514/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0101\n",
      "Epoch 515/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0100\n",
      "Epoch 516/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0098\n",
      "Epoch 517/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 518/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0094\n",
      "Epoch 519/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 520/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 521/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0093\n",
      "Epoch 522/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 523/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 524/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.006 - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 525/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 526/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 527/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 529/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 530/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 531/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 532/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0094\n",
      "Epoch 533/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 534/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0097\n",
      "Epoch 535/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 536/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 537/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 538/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0100\n",
      "Epoch 539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 540/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 541/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 542/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 543/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 544/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 545/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0094\n",
      "Epoch 547/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 548/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 549/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0099\n",
      "Epoch 550/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0098\n",
      "Epoch 551/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 552/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 553/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 554/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0098\n",
      "Epoch 556/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 558/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 559/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.003 - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 560/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 561/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0101\n",
      "Epoch 562/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0101\n",
      "Epoch 563/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 564/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.006 - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 565/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 566/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0098\n",
      "Epoch 567/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0100\n",
      "Epoch 568/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 569/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 570/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0101\n",
      "Epoch 571/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 572/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 573/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 574/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 575/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 576/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 577/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 578/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 579/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 580/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0103\n",
      "Epoch 581/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 582/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 583/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 584/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 585/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 586/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 587/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 588/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 589/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 590/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 591/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 592/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 593/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 594/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 595/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 596/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 597/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 598/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 599/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 600/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 601/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 602/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 603/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 604/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 605/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 606/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 607/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 608/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 609/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 610/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 611/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 612/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 613/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 614/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 615/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 616/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 617/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 618/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 619/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 620/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 621/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 622/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 623/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 624/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 625/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 626/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0100\n",
      "Epoch 627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 628/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 629/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 630/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 631/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 632/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 634/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 635/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 636/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0097\n",
      "Epoch 637/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 638/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0104\n",
      "Epoch 639/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 640/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 641/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 642/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0105\n",
      "Epoch 643/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0101\n",
      "Epoch 644/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 645/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 646/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 647/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 650/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 651/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 652/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 653/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0101\n",
      "Epoch 654/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0105\n",
      "Epoch 655/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0097\n",
      "Epoch 656/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 657/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 658/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0104\n",
      "Epoch 659/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 660/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 662/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 663/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 664/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 665/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0104\n",
      "Epoch 666/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 667/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0107\n",
      "Epoch 668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0098\n",
      "Epoch 669/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0104\n",
      "Epoch 670/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 671/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 672/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 673/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 674/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 675/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 676/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 677/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 678/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 679/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 680/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 681/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 682/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 684/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0104\n",
      "Epoch 685/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 686/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 687/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 689/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 690/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.004 - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 691/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 692/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 693/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 697/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 698/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 699/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 700/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 701/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 702/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 703/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 704/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0105\n",
      "Epoch 705/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 706/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0104\n",
      "Epoch 707/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 708/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 709/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 710/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 712/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 713/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 714/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 715/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 716/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 717/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 718/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 719/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 720/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 721/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 722/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 723/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 724/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 725/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 726/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 727/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 728/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 729/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 730/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 731/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 732/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 733/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 734/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 735/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.003 - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 736/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 737/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 738/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0105\n",
      "Epoch 739/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0105\n",
      "Epoch 740/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0109\n",
      "Epoch 741/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 742/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0108\n",
      "Epoch 743/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 744/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0105\n",
      "Epoch 745/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 746/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 748/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.009 - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 749/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 750/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 751/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 752/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0105\n",
      "Epoch 754/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 755/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 756/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0105\n",
      "Epoch 757/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0106\n",
      "Epoch 758/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0107\n",
      "Epoch 759/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0108\n",
      "Epoch 760/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0105\n",
      "Epoch 761/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 762/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 763/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 764/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 765/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 766/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 767/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0110\n",
      "Epoch 768/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0106\n",
      "Epoch 769/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0106\n",
      "Epoch 770/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 771/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 772/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0106\n",
      "Epoch 773/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0110\n",
      "Epoch 774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0102\n",
      "Epoch 775/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.004 - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0113\n",
      "Epoch 776/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0110\n",
      "Epoch 777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0114\n",
      "Epoch 778/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0114\n",
      "Epoch 780/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0107\n",
      "Epoch 781/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 782/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0109\n",
      "Epoch 783/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 784/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0107\n",
      "Epoch 785/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 788/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 792/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 793/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0097\n",
      "Epoch 794/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 795/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 796/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 797/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0097\n",
      "Epoch 798/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0097\n",
      "Epoch 799/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0097\n",
      "Epoch 804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 805/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.004 - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 806/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 809/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 810/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 811/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 812/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 816/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 817/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 818/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0096\n",
      "Epoch 819/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0105\n",
      "Epoch 820/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0104\n",
      "Epoch 821/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0104\n",
      "Epoch 822/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0104\n",
      "Epoch 823/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 824/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0102\n",
      "Epoch 825/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0100\n",
      "Epoch 826/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 827/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 829/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 830/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 831/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 832/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 833/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 834/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 835/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 836/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 837/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 838/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 839/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 841/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0105\n",
      "Epoch 842/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 843/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 844/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 845/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 846/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 847/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 848/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 850/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 851/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 852/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 853/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 854/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 855/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 856/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 857/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 858/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 859/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 860/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 861/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 862/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 863/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 864/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 865/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 866/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 868/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 871/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 872/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 875/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 876/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 877/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 878/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 879/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0107\n",
      "Epoch 880/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0101\n",
      "Epoch 881/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 882/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 884/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 885/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 886/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 887/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 888/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 889/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 890/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 891/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 892/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 896/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0104\n",
      "Epoch 898/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 907/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 908/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 909/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 910/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 911/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 914/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 917/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 918/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 919/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 922/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 923/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 925/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 926/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 927/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 930/2000\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 931/2000\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 932/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 933/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0109\n",
      "Epoch 934/2000\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0055 - val_loss: 0.0104\n",
      "Epoch 935/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 936/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0107\n",
      "Epoch 937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 938/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0108\n",
      "Epoch 939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 940/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 941/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 944/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 945/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 950/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 951/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 952/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 953/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 954/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0105\n",
      "Epoch 956/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 957/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 958/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 960/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 961/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 962/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0106\n",
      "Epoch 963/2000\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 964/2000\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 966/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 967/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 970/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 971/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 974/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 975/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 976/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 977/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 978/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 979/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 980/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 981/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 982/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 983/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 984/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 985/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 986/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 987/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 988/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 990/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 991/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 992/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 993/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 994/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 998/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 1000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1001/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 1002/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1003/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1004/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 1005/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1006/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1007/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1008/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1009/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 1010/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1011/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 1012/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 1013/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 1014/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1015/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1016/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1017/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 1018/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1019/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1020/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1021/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1022/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1023/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1024/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1025/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1026/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1027/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1028/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1029/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1030/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1031/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1032/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 1033/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1034/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1035/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1036/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1037/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1038/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1039/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1040/2000\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1041/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1042/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 1043/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1044/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1045/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 1046/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1047/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1048/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1049/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1050/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1051/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 1052/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1053/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1054/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 1055/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 1056/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 1057/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1058/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1059/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 1060/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1061/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1062/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 1063/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1064/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1065/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1066/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1067/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 1068/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 1069/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1070/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1071/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1072/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1073/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1074/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1075/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1076/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1077/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1078/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1079/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1080/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1081/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1082/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1083/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1084/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1085/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1086/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1087/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1088/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1089/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 1090/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 1091/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0097\n",
      "Epoch 1092/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1093/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1094/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1095/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1096/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1097/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1098/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1099/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 1100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1101/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1102/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1103/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1105/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 1106/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1107/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1109/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1111/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 1114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0106\n",
      "Epoch 1116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1118/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1119/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1120/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 1121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 1122/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1123/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1124/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1125/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 1126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1129/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1132/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 1133/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 1134/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1136/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1137/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1138/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 1139/2000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1140/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1141/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1142/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1143/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1144/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1145/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1146/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1147/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1149/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1150/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0106\n",
      "Epoch 1152/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1153/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 1155/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0107\n",
      "Epoch 1156/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0110\n",
      "Epoch 1157/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 1158/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1159/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1160/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 1161/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1162/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1163/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1165/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1166/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1170/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1171/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1172/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1173/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 1174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0105\n",
      "Epoch 1175/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0108\n",
      "Epoch 1176/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 1177/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1181/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1182/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1183/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1184/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0106\n",
      "Epoch 1185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1186/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 1187/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1188/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1189/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1190/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 1192/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1193/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1194/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1195/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 1196/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1197/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1198/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 1199/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1200/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1201/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1202/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1204/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 1205/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0105\n",
      "Epoch 1206/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1207/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 1208/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1209/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1210/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1212/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1213/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1214/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1215/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1216/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1220/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1221/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1225/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1226/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1227/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1229/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1230/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1232/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1233/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1236/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1237/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1238/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1239/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 1240/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1241/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1244/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1245/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1246/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1247/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1248/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1251/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1252/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1253/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1254/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1255/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1256/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1257/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1258/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1259/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1260/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1261/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1262/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1263/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1264/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1265/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1266/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1267/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1268/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 1269/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1270/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 1271/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1272/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1273/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 1274/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 1275/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1276/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1277/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1278/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1279/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.005 - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0097\n",
      "Epoch 1280/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1281/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1282/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0107\n",
      "Epoch 1283/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1284/2000\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0052 - val_loss: 0.0104ETA: 0s - loss: 0.00\n",
      "Epoch 1285/2000\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 1286/2000\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1287/2000\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0105\n",
      "Epoch 1288/2000\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 1289/2000\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1290/2000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0097\n",
      "Epoch 1291/2000\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1292/2000\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1293/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.005 - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1294/2000\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0104\n",
      "Epoch 1295/2000\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1296/2000\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1297/2000\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1298/2000\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1299/2000\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1300/2000\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1301/2000\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 1302/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1303/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1304/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0105\n",
      "Epoch 1305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1306/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1308/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0107\n",
      "Epoch 1309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 1313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1315/2000\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1316/2000\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1317/2000\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1318/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1319/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1320/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1321/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1322/2000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1323/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1324/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1325/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 1327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1328/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1331/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1332/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 1333/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 1334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1335/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1338/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1339/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1340/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 1341/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 1342/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 1343/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0105\n",
      "Epoch 1344/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1345/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 1346/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 1347/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1348/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1349/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1350/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1351/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1353/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1354/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1356/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1358/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1359/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1360/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1361/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1362/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1363/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0107\n",
      "Epoch 1364/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1365/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1366/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1367/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1368/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1369/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1370/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 1371/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 1372/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0096\n",
      "Epoch 1373/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1374/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0097\n",
      "Epoch 1375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1378/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1379/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1380/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1382/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1383/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1385/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0100\n",
      "Epoch 1387/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 1388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1391/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0097\n",
      "Epoch 1393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1395/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1396/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1397/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1398/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1399/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1400/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1401/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1402/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1404/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1407/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1409/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1410/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1411/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1412/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1413/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1414/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1415/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1416/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1417/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 1418/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 1419/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1420/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1421/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1423/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1424/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1425/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1426/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1427/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1428/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0105\n",
      "Epoch 1429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1435/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1438/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1439/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1440/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1441/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1442/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1443/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0108\n",
      "Epoch 1445/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0097\n",
      "Epoch 1446/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0110\n",
      "Epoch 1449/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 1450/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1451/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1452/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0105\n",
      "Epoch 1453/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0108\n",
      "Epoch 1454/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 1455/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1456/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 1457/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0109\n",
      "Epoch 1458/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 1459/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0104\n",
      "Epoch 1460/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1461/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1462/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.005 - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1463/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1464/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1465/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1466/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1467/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1468/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1469/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1470/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1471/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0105\n",
      "Epoch 1472/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 1473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1475/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0105\n",
      "Epoch 1476/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1477/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1478/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1479/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1480/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0104\n",
      "Epoch 1481/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1482/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1483/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1484/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1485/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1486/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1487/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0104\n",
      "Epoch 1488/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1489/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1490/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1491/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1492/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1493/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1494/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 1495/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1496/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1497/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1498/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0106\n",
      "Epoch 1499/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1501/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 1502/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1503/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1504/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1505/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1506/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1507/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1508/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1509/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1510/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1511/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1512/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1514/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1515/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1516/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1517/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1518/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1519/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1520/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1521/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1522/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1523/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1524/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1525/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1526/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1527/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.004 - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1528/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1529/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1530/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 1532/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1533/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1534/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1535/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1536/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1537/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1538/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1540/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1541/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1545/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0097\n",
      "Epoch 1546/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1547/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1548/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1549/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1550/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1551/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1552/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1553/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1554/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1555/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1556/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1557/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1558/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1559/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1560/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1561/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1562/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.003 - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1563/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1564/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1566/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1567/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1568/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1569/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1570/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1571/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1572/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1573/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 1574/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1575/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1576/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1577/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1579/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1580/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1581/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1582/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1583/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1584/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1585/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1586/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1587/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1588/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1589/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0106\n",
      "Epoch 1590/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0097\n",
      "Epoch 1592/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1593/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1594/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1595/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1596/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1597/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1598/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1599/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0108\n",
      "Epoch 1600/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1601/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1602/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1603/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1605/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1606/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1607/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1608/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1609/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1610/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1611/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1612/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1613/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1614/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1615/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1616/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1618/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1619/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1620/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1621/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1622/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1623/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1624/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1625/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1626/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1627/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1628/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1629/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1630/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1631/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1632/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1633/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1634/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1635/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1637/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1638/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1639/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0104\n",
      "Epoch 1640/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1641/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1642/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1643/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1644/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1645/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0106\n",
      "Epoch 1646/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1647/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1648/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1649/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1650/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1651/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1652/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1653/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0096\n",
      "Epoch 1654/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1655/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1656/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0096\n",
      "Epoch 1657/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1658/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1659/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1660/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1661/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1662/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1663/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1664/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1665/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1666/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1667/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1668/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1669/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1671/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1672/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1673/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1674/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1675/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1676/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1677/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1678/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1679/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1680/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1681/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1682/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1684/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1685/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.004 - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1686/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1687/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1688/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.006 - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1689/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0097\n",
      "Epoch 1690/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1691/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1692/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1693/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1694/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1695/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1697/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 1699/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1700/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1701/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1702/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1703/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1704/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1705/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1706/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1707/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1708/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1709/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1710/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1711/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1712/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1713/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1714/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1715/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1716/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1717/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1718/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1719/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.004 - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1720/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1721/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0101\n",
      "Epoch 1722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1723/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1724/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0101\n",
      "Epoch 1725/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1726/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1727/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1728/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1729/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1730/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1731/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1732/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1733/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1734/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1735/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1736/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1738/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1739/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0102\n",
      "Epoch 1741/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.006 - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1742/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 1743/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1744/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0102\n",
      "Epoch 1746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1747/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0101\n",
      "Epoch 1754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0107\n",
      "Epoch 1755/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1756/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1757/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0105\n",
      "Epoch 1758/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1759/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1760/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1761/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1762/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1763/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0102\n",
      "Epoch 1765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1767/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1769/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1770/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1772/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1773/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0105\n",
      "Epoch 1775/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1777/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1778/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1780/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1781/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1782/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1784/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1785/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0101\n",
      "Epoch 1789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 1795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0102\n",
      "Epoch 1798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 1799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0102\n",
      "Epoch 1802/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1803/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1804/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1805/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.004 - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1806/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1807/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1808/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1809/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1810/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1811/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1812/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0102\n",
      "Epoch 1813/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1814/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1815/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1818/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1819/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1820/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1821/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1824/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1826/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1827/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1828/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1829/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1831/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0102\n",
      "Epoch 1833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1834/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1836/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1837/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1839/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1840/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1841/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1842/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1843/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1844/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1845/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1846/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1848/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0101\n",
      "Epoch 1849/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1850/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0101\n",
      "Epoch 1851/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1852/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1853/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1854/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1855/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0106\n",
      "Epoch 1857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1860/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1861/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1862/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1863/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1864/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1865/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0104\n",
      "Epoch 1866/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1867/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1868/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1869/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1870/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1871/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1873/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 1876/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1877/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0096\n",
      "Epoch 1878/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1879/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 1880/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 1881/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1882/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1883/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 1884/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 1885/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1886/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1887/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1888/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1890/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1891/2000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1892/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1893/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1894/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1895/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1896/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1897/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1898/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1899/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1900/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1901/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1902/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0096\n",
      "Epoch 1903/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 1904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1905/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0105\n",
      "Epoch 1906/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 1907/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1908/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1909/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1910/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0101\n",
      "Epoch 1911/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.004 - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1912/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0102\n",
      "Epoch 1914/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1915/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1916/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1918/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1921/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0102\n",
      "Epoch 1923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1925/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1926/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1927/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1928/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1929/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1930/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1931/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1932/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1933/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1934/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1935/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1936/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 1937/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1938/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 1939/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1940/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1941/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1942/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 1943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 1944/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1945/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 1949/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1952/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1953/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 1954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 1955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1956/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1957/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 1959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1960/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1961/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0101\n",
      "Epoch 1963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0096\n",
      "Epoch 1964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 1965/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1967/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 1968/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0096\n",
      "Epoch 1969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1971/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 1973/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 1977/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1978/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 1979/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 1980/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1981/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 1982/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 1984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1985/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1986/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1987/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 1989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 1990/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 1991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 1993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 1994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 1995/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1996/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 1997/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0098\n",
      "Epoch 1998/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0095\n",
      "Epoch 1999/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 2000/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0103\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   validation_data = (X_test, y_test),\n",
    "                   batch_size = 256,\n",
    "                    epochs = 2000\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c13536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b81c5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('dark_background')\n",
    "# Check out our train loss and test loss over epochs.\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Set figure size.\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Generate line plot of training, testing loss over epochs.\n",
    "plt.plot(train_loss, label='Training Loss', color=colors.to_rgba('b',0.8))\n",
    "plt.plot(test_loss, label='Testing Loss', color='orange')\n",
    "\n",
    "# Set title\n",
    "plt.title('Training and Testing Loss by Epoch', fontsize = 25)\n",
    "plt.xlabel('Epoch', fontsize = 18)\n",
    "plt.ylabel('mse', fontsize = 18)\n",
    "\n",
    "plt.legend(fontsize = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2975dc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41212705, 0.36023986, 0.38548124, ..., 0.85257006, 0.8339382 ,\n",
       "       0.8100111 ], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1fcc891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(model.predict(X_train).flatten())+list(model.predict(X_test).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ddf6baab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4976"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e32a833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d5c9e1d700>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(tweet_rate_df[0][:5000])\n",
    "plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e94ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tensorflow]",
   "language": "python",
   "name": "conda-env-.conda-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
